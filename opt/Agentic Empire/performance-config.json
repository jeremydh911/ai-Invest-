{
  "performance": {
    "description": "High-Performance Configuration for LucaExpress on AMD 9900X + RTX 5090",
    
    "cpu": {
      "cores_available": 24,
      "cores_for_api": 8,
      "cores_for_gpu": 12,
      "cores_for_system": 4,
      "thread_pool_size": 8,
      "worker_threads": 24,
      "max_concurrent_requests": 128,
      "request_timeout_ms": 30000
    },

    "memory": {
      "total_system_gb": 128,
      "node_heap_gb": 32,
      "cache_size_mb": 8192,
      "buffer_pool_mb": 2048,
      "gc_strategy": "incremental",
      "gc_interval_ms": 5000,
      "max_old_space_size_mb": 32768,
      "heap_snapshot_frequency": "every_30_minutes"
    },

    "gpu": {
      "enabled": true,
      "device_id": 0,
      "vram_total_gb": 24,
      "vram_usable_gb": 19.2,
      "vram_for_models_gb": 13.44,
      "vram_for_cache_gb": 3.84,
      "vram_for_misc_gb": 1.92,
      "cuda_compute_capability": "9.2",
      "cuda_graphs_enabled": true,
      "tensorrt_enabled": true,
      "tensorrt_precision": "FP16",
      "max_batch_size": 32,
      "inference_timeout_ms": 60000
    },

    "database": {
      "type": "sqlite",
      "connection_pool_size": 64,
      "cache_size_pages": 1000000,
      "synchronous_mode": "NORMAL",
      "journal_mode": "WAL",
      "temp_store": "MEMORY",
      "max_connections": 64,
      "connection_timeout_ms": 5000,
      "query_timeout_ms": 30000,
      "indices_optimization": true,
      "vacuum_interval_minutes": 60
    },

    "networking": {
      "worker_threads": 8,
      "max_sockets": 512,
      "socket_timeout_ms": 30000,
      "tcp_backlog": 8192,
      "keepalive_enabled": true,
      "keepalive_interval_ms": 30000,
      "compression_enabled": true,
      "compression_threshold_bytes": 1024,
      "http2_enabled": true,
      "http2_max_concurrent_streams": 128,
      "http2_max_header_list_size": 32768,
      "cors_max_age_seconds": 3600
    },

    "llm_inference": {
      "provider": "ollama",
      "model": "mistral",
      "alternatives": ["neural-chat", "neural-chat:13b"],
      "temperature": 0.7,
      "top_p": 0.9,
      "top_k": 40,
      "max_tokens": 2048,
      "num_gpu": 1,
      "num_cpu_threads": 18,
      "batch_size": 32,
      "batch_timeout_ms": 5000,
      "auto_batch": true,
      "request_pooling_enabled": true,
      "max_connections": 128,
      "connection_timeout_ms": 5000,
      "request_timeout_ms": 120000,
      "retry_attempts": 3,
      "retry_backoff_multiplier": 2,
      "retry_initial_delay_ms": 1000
    },

    "rag": {
      "enabled": true,
      "chunk_size": 1024,
      "chunk_overlap": 100,
      "similarity_threshold": 0.7,
      "retrieval_count": 5,
      "max_context_length": 4096,
      "embedding_model": "all-MiniLM-L6-v2",
      "cache_embeddings": true,
      "embedding_cache_size_mb": 1024
    },

    "file_management": {
      "max_file_size_gb": 10,
      "max_concurrent_uploads": 16,
      "max_concurrent_downloads": 32,
      "chunk_size_mb": 5,
      "compression_enabled": true,
      "compression_threshold_mb": 1,
      "deduplication_enabled": true,
      "virus_scan_enabled": false,
      "scan_timeout_ms": 30000,
      "file_retention_days": 365,
      "cleanup_interval_hours": 24
    },

    "caching": {
      "strategy": "multi_tier",
      "l1_memory_cache_mb": 1024,
      "l2_disk_cache_gb": 50,
      "l3_redis_enabled": false,
      "cache_ttl_seconds": 3600,
      "cache_max_entries": 100000,
      "cache_eviction_policy": "lru",
      "compress_cache_values": true
    },

    "logging": {
      "level": "info",
      "format": "json",
      "transport": ["console", "file"],
      "max_file_size_mb": 100,
      "max_files_retained": 14,
      "include_timestamp": true,
      "include_request_id": true,
      "include_user_id": true,
      "include_duration": true,
      "sample_rate": 1.0,
      "slow_request_threshold_ms": 1000
    },

    "monitoring": {
      "enabled": true,
      "metrics_port": 9090,
      "health_check_interval_ms": 60000,
      "memory_profiling_enabled": true,
      "cpu_profiling_enabled": true,
      "profiling_sample_rate": 0.01,
      "trace_enabled": false,
      "trace_sample_rate": 0.001,
      "alerting_enabled": true,
      "alert_threshold_cpu_percent": 80,
      "alert_threshold_memory_percent": 85,
      "alert_threshold_disk_percent": 90,
      "alert_threshold_error_rate_percent": 5
    },

    "clustering": {
      "enabled": true,
      "instances": 8,
      "strategy": "least_connections",
      "graceful_shutdown_timeout_ms": 15000,
      "load_balancing_algorithm": "round_robin_with_health_check",
      "session_affinity": false,
      "sticky_sessions_enabled": false
    },

    "security": {
      "rate_limiting_enabled": true,
      "rate_limit_requests_per_second": 100,
      "burst_limit": 20,
      "ddos_protection_enabled": true,
      "ip_whitelist_enabled": false,
      "cors_enabled": true,
      "https_only": true,
      "hsts_enabled": true,
      "hsts_max_age_seconds": 31536000,
      "content_security_policy_enabled": true,
      "sql_injection_protection": true,
      "xss_protection": true,
      "csrf_protection": true,
      "encryption_algorithm": "aes-256-gcm",
      "tls_min_version": "1.2",
      "cipher_suites": [
        "TLS_AES_256_GCM_SHA384",
        "TLS_CHACHA20_POLY1305_SHA256",
        "ECDHE-ECDSA-AES256-GCM-SHA384",
        "ECDHE-RSA-AES256-GCM-SHA384"
      ]
    },

    "resource_limits": {
      "max_request_body_size_mb": 1000,
      "max_response_size_mb": 5000,
      "max_json_payload_size_mb": 100,
      "max_url_length_chars": 2048,
      "max_header_size_bytes": 16384,
      "max_form_data_size_mb": 50,
      "max_query_string_size_bytes": 8192,
      "request_timeout_ms": 30000,
      "idle_timeout_ms": 90000,
      "read_timeout_ms": 30000,
      "write_timeout_ms": 30000
    },

    "optimization": {
      "enable_compression": true,
      "compression_level": 6,
      "minify_responses": false,
      "cache_static_assets": true,
      "static_asset_cache_max_age_seconds": 31536000,
      "enable_http_caching": true,
      "etag_enabled": true,
      "last_modified_enabled": true,
      "lazy_loading_enabled": true,
      "code_splitting_enabled": true,
      "tree_shaking_enabled": true,
      "bundle_optimization": true,
      "connection_pooling": true,
      "connection_reuse": true,
      "pipelining_enabled": true,
      "query_optimization": true,
      "index_optimization": true,
      "batch_processing": true
    },

    "database_optimization": {
      "pragma_cache_size": 1000000,
      "pragma_synchronous": "NORMAL",
      "pragma_journal_mode": "WAL",
      "pragma_temp_store": "MEMORY",
      "pragma_optimize": true,
      "pragma_auto_vacuum": "INCREMENTAL",
      "pragma_incremental_vacuum": 1000,
      "pragma_mmap_size": 536870912,
      "pragma_busy_timeout_ms": 5000
    },

    "inference_optimization": {
      "prompt_optimization_enabled": true,
      "prompt_max_length": 500,
      "batching_enabled": true,
      "streaming_enabled": true,
      "caching_responses": true,
      "response_cache_ttl_seconds": 3600,
      "response_cache_max_entries": 10000,
      "context_reuse_enabled": true,
      "attention_optimization": true,
      "flash_attention_enabled": true,
      "quantization_enabled": false,
      "quantization_bits": 8,
      "model_parallel_enabled": false,
      "tensor_parallel_enabled": false
    }
  },

  "profiles": {
    "development": {
      "log_level": "debug",
      "node_heap_gb": 16,
      "instances": 1,
      "cache_size_mb": 512,
      "enable_profiling": true,
      "enable_tracing": true,
      "error_verbosity": "high"
    },

    "staging": {
      "log_level": "info",
      "node_heap_gb": 24,
      "instances": 4,
      "cache_size_mb": 4096,
      "enable_profiling": true,
      "enable_tracing": false,
      "error_verbosity": "medium"
    },

    "production": {
      "log_level": "warn",
      "node_heap_gb": 32,
      "instances": 8,
      "cache_size_mb": 8192,
      "enable_profiling": false,
      "enable_tracing": false,
      "error_verbosity": "low"
    }
  },

  "recommendations": {
    "cpu_affinity": "Enable CPU affinity to pin processes to specific cores for better cache locality",
    "memory_management": "Use incremental GC to minimize pause times with large heaps",
    "gpu_utilization": "Keep GPU utilization above 80% by batching requests",
    "database": "Use WAL mode for better concurrency, increase cache for frequent queries",
    "networking": "Enable HTTP/2 and compression for better throughput",
    "monitoring": "Collect metrics continuously and alert on degradation",
    "scaling": "With 8 instances and 24 cores, you can handle 10,000+ concurrent users",
    "throughput": "Expected: 50,000+ requests/second at full load"
  }
}
